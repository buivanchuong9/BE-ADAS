# ADAS Backend - Production Ready FastAPI
# Version 3.0.0 - Competition Build
# Cloudflare Tunnel Compatible

import asyncio
import json
import logging
import os
import time
import uuid
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Dict, List, Optional

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, Body
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

from vision.detector import decode_base64_image, run_detection
from vision.lane import detect_lanes

# Basic JSON logging
logging.basicConfig(
    level=logging.INFO,
    format='{"time":"%(asctime)s","level":"%(levelname)s","message":"%(message)s","module":"%(module)s"}',
)
logger = logging.getLogger("vision-backend")

# Thread pool for CPU-bound inference
executor = ThreadPoolExecutor(max_workers=max(os.cpu_count() or 4, 4))

app = FastAPI(
    title="ADAS Vision Backend",
    version="1.0.0",
    description="Real-time vision inference (YOLO + lane) with FastAPI/WebSocket",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class FrameRequest(BaseModel):
    frame: Optional[str] = Field(
        None,
        description="Base64 encoded image (JPEG/PNG). Can be empty for testing.",
        example="data:image/jpeg;base64,/9j/4AAQSkZJRg..."
    )
    tasks: Optional[List[str]] = Field(
        None,
        description="Tasks to run: 'detect', 'lane', 'collision'. Default: ['detect', 'lane']",
        example=["detect", "lane"]
    )
    options: Optional[Dict[str, Any]] = Field(
        None,
        description="Additional options for processing",
        example={"confidence_threshold": 0.5}
    )


class DetectionResponse(BaseModel):
    label: str
    confidence: float
    bbox: List[float]


class FrameResponse(BaseModel):
    detections: List[DetectionResponse] = Field(default_factory=list)
    lanes: Dict[str, Any] = Field(default_factory=dict)
    collision: Optional[Dict[str, Any]] = Field(None, description="Collision detection results")
    elapsed_ms: float


@app.middleware("http")
async def add_correlation_id(request: Request, call_next):
    cid = request.headers.get("x-correlation-id", str(uuid.uuid4()))
    request.state.correlation_id = cid
    response = await call_next(request)
    response.headers["x-correlation-id"] = cid
    return response


@app.on_event("startup")
async def startup_event():
    """Log all registered routes on startup for debugging"""
    logger.info("=" * 80)
    logger.info("üöÄ ADAS Vision Backend Starting...")
    logger.info(f"   Host: 0.0.0.0")
    logger.info(f"   Port: 52000")
    logger.info(f"   Cloudflare Tunnel Compatible: ‚úÖ")
    logger.info("=" * 80)
    logger.info("üìç Registered Routes:") = Body(...)):
    """
    Process a single frame with YOLO detection and lane detection.
    
    Flexible endpoint that accepts:
    - Empty body: returns empty results
    - { "frame": "test" }: returns empty results (test mode)
    - { "frame": "<base64>" }: processes frame with default tasks
    - { "frame": "<base64>", "tasks": ["detect"] }: runs only specified tasks
    """
    start_time = time.perf_counter()
    
    # Default values
    detections = []
    lanes = {}
    collision = None
    tasks = payload.tasks or ["detect", "lane"]
    
    logger.info(json.dumps({
        "event": "request_received",
        "has_frame": bool(payload.frame),
        "tasks": tasks,
        "options": payload.options or {}
    }))
    
    # Handle missing or invalid frame
    if not payload.frame or len(payload.frame) < 20:
        logger.info(json.dumps({
            "event": "empty_or_test_request",
            "frame_length": len(payload.frame) if payload.frame else 0
        }))
        elapsed_ms = round((time.perf_counter() - start_time) * 1000, 2)
        return {
            "detections": [],
            "lanes": {},
            "collision": None,
            "elapsed_ms": elapsed_ms
        }
    
    # Try to decode and process frame
    try:
        image = decode_base64_image(payload.frame)
        loop = asyncio.get_running_loop()
        
        # Run detection if requested
        if "detect" in tasks or "detection" in tasks:
            try:
                detections, detect_elapsed = await loop.run_in_executor(
                    executor, run_detection, image
                )
                logger.info(json.dumps({
                    "event": "detection_completed",
                    "count": len(detections),
                    "elapsed_ms": round(detect_elapsed * 1000, 2)
                }))
            except Exception as e:
                logger.error(f"Detection failed: {e}")
                detections = []
        
        # Run lane detection if requested
        if "lane" in tasks or "lanes" in tasks:
            try:
                lanes = detect_lanes(image)
                logger.info(json.dumps({
                    "event": "lane_detection_completed",
                    "lanes_found": lanes.get("count", 0)
                }))
            except Exception as e:
                logger.error(f"Lane detection failed: {e}")
                lanes = {}
        
        # Collision detection placeholder (can be implemented later)
        if "collision" in tasks:
            collision = {"status": "not_implemented"}
            logger.info("Collision detection requested but not implemented")
        
    except Exception as e:
        logger.error(json.dumps({
            "event": "frame_processing_error",
            "error": str(e),
            "error_type": type(e).__name__
        }))
        # Return empty results on error instead of crashing
        detections = []
        lanes = {}
        collision = None
    
    elapsed_ms = round((time.perf_counter() - start_time) * 1000, 2)
    
    logger.info(json.dumps({
        "event": "frame_processed",
        "detections": len(detections),
        "lanes": lanes.get("count", 0) if isinstance(lanes, dict) else 0,
        "elapsed_ms": elapsed_ms,
        "tasks_executed": tasks
    }))
    
    return {
        "detections": detections,
        "lanes": lanes,
        "collision": collision,
        "elapsed_ms": elapsed_ms
    logger.info(
        json.dumps(
            {
                "event": "frame_processed",
                "detections": len(detections),
                "lanes": lanes.get("count", 0),
                "elapsed_ms": round(elapsed * 1000, 2),
            }
        )
    )

    return {
        "detections": detections,
        "lanes": lanes,
        "elapsed_ms": round(elapsed * 1000, 2),
    }


@app.websocket("/vision/stream")
async def vision_stream(ws: WebSocket):
    await ws.accept()
    try:
        while True:
            message = await ws.receive_text()
            data = json.loads(message)
            frame_b64 = data.get("frame")
            if not frame_b64:
                await ws.send_json({"error": "missing frame"})
                continue

            image = decode_base64_image(frame_b64)
            loop = asyncio.get_running_loop()
            detections, elapsed = await loop.run_in_executor(executor, run_detection, image)
            lanes = detect_lanes(image)

            await ws.send_json(
                {
                    "type": "frame_result",
                    "detections": detections,
                    "lanes": lanes,
                    "elapsed_ms": round(elapsed * 1000, 2),
                    "timestamp": time.time(),
                }
            )
    except WebSocketDisconnect:
        logger.info("WebSocket disconnected")
    except Exception as e:
        logger.exception("WebSocket error: %s", e)
        await ws.close(code=1011, reason=str(e))


if __name__ == "__main__":
    logger.info("üî• Starting ADAS Backend on 0.0.0.0:52000")
    uvicorn.run("main:app", host="0.0.0.0", port=52000, reload=False, log_level="info")
